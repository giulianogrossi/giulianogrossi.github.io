{"version":"1","records":[{"hierarchy":{"lvl1":"Il suono"},"type":"lvl1","url":"/cap1-suono","position":0},{"hierarchy":{"lvl1":"Il suono"},"content":"","type":"content","url":"/cap1-suono","position":1},{"hierarchy":{"lvl1":"Il suono","lvl3":"Introduzione"},"type":"lvl3","url":"/cap1-suono#introduzione","position":2},{"hierarchy":{"lvl1":"Il suono","lvl3":"Introduzione"},"content":"","type":"content","url":"/cap1-suono#introduzione","position":3},{"hierarchy":{"lvl1":"Il suono","lvl2":"La fisica del suono"},"type":"lvl2","url":"/cap1-suono#la-fisica-del-suono","position":4},{"hierarchy":{"lvl1":"Il suono","lvl2":"La fisica del suono"},"content":"La fisica del suono è una branca della scienza che si occupa dello studio delle onde sonore, della loro propagazione e delle loro interazioni con l’ambiente circostante. Il suono è un fenomeno onnipresente nella nostra vita quotidiana, essenziale per la comunicazione e l’interazione con il mondo. Comprendere la fisica del suono significa analizzare le sue proprietà fondamentali, come la natura ondulatoria, la velocità, la frequenza, l’ampiezza e l’energia che le onde sonore trasportano.\n\nSul piano percettivo, il suono è una sensazione uditiva provocata da una variazione della pressione dell’aria. L’onda sonora generata dalla vibrazione di un corpo elastico arriva al nostro orecchio dopo aver viaggiato lungo un altro materiale elastico (nella nostra esperienza più comune l’aria). Gli elementi necessari perché si verifichi un suono sono dunque tre:\n\nla sorgente sonora (il corpo vibrante)\n\nil mezzo di trasmissione dell’onda sonora (l’ambiente, anche non omogeneo, dove il suono si propaga)\n\nil ricevitore (l’ orecchio e il cervello)\n\nDella natura delle vibrazioni e delle onde sonore e della loro propagazione nel mezzo si occupa la acustica fisica, del rapporto tra onda sonora e il ricevente (il sistema orecchio – cervello), e quindi di come l’uomo interpreta i segnali acustici, si occupa la psicoacustica.","type":"content","url":"/cap1-suono#la-fisica-del-suono","position":5},{"hierarchy":{"lvl1":"Il suono","lvl3":"La natura fisica del suono","lvl2":"La fisica del suono"},"type":"lvl3","url":"/cap1-suono#la-natura-fisica-del-suono","position":6},{"hierarchy":{"lvl1":"Il suono","lvl3":"La natura fisica del suono","lvl2":"La fisica del suono"},"content":"Il suono è un’onda meccanica che si propaga attraverso un mezzo, sia esso solido, liquido o gassoso. A differenza delle onde elettromagnetiche, come la luce, le onde sonore hanno bisogno di un mezzo per spostarsi e non possono propagarsi nel vuoto. La propagazione del suono avviene per mezzo di vibrazioni che si trasmettono da una particella all’altra all’interno del mezzo: quando un oggetto vibra, genera una serie di compressioni e rarefazioni nell’aria circostante (o in altri mezzi), producendo l’onda sonora.\n\nNel contesto del suono e della fisica, le onde si distinguono in onde longitudinali e onde trasversali e si caratterizzano per la direzione del movimento delle particelle rispetto alla propagazione dell’onda:\n\nOnde Longitudinali: Le onde sonore sono generalmente onde longitudinali, dove le particelle del mezzo (ad esempio, aria, acqua o solido) vibrano parallelamente alla direzione di propagazione dell’onda. Le onde sonore si propagano creando regioni di compressione (dove le particelle sono più dense) e rarefazione (dove le particelle sono meno dense). Un esempio comune è il suono che viaggia nell’aria: quando un oggetto vibra, genera onde di compressione e rarefazione che si propagano attraverso il mezzo.\n\nOnde Trasversali: Le onde trasversali, invece, sono caratterizzate dal fatto che le particelle del mezzo oscillano perpendicolarmente alla direzione di propagazione dell’onda. Sebbene questo tipo di onda non rappresenti il modo comune con cui il suono si propaga nei fluidi come l’aria o l’acqua, può essere osservato nei solidi, dove onde di taglio possono propagarsi attraverso il materiale con le particelle che si muovono perpendicolarmente alla direzione dell’onda.\n\nIn sintesi, il suono nell’aria è principalmente un fenomeno longitudinale, mentre le onde trasversali sono più comuni in contesti come le onde sismiche o le vibrazioni in corde tese.\n\nUn esempio classico di onde sonore longitudinali è il suono che si propaga nell’aria. Quando si parla, si emette un suono facendo vibrare le corde vocali, che a loro volta creano compressioni e rarefazioni nelle molecole d’aria.\n\nLe particelle d’aria oscillano avanti e indietro parallelamente alla direzione in cui l’onda sonora si propaga, caratterizzando così il suono come un’onda longitudinale. Nell’immagine qui sotto si rappresentano le onde sonore longitudinali attraverso un grafico (realistico) di spostamento delle particelle per evidenziare le dinamiche dell’onda.\n\nUn esempio comune di onde trasversali è la propagazione delle onde sulla superficie dell’acqua. In queste onde, le particelle d’acqua si muovono perpendicolarmente alla direzione di propagazione dell’onda stessa. Quando si getta un sasso in uno stagno, si osservano onde che si propagano verso l’esterno formando cerchi concentrici, mentre le particelle d’acqua oscillano su e giù. Altri esempi includono:\n\nOnde elettromagnetiche (come la luce e le onde radio), dove i campi elettrici e magnetici oscillano perpendicolarmente alla direzione di propagazione.\n\nOnde su una corda: Se si scuote una corda tesa su e giù, le onde viaggiano lungo la corda, ma il movimento delle particelle della corda è perpendicolare alla direzione dell’onda.","type":"content","url":"/cap1-suono#la-natura-fisica-del-suono","position":7},{"hierarchy":{"lvl1":"Il suono","lvl3":"Velocità e propagazione del suono nei diversi materiali","lvl2":"La fisica del suono"},"type":"lvl3","url":"/cap1-suono#velocit-e-propagazione-del-suono-nei-diversi-materiali","position":8},{"hierarchy":{"lvl1":"Il suono","lvl3":"Velocità e propagazione del suono nei diversi materiali","lvl2":"La fisica del suono"},"content":"Le onde più semplici sono quelle sinusoidali, formate da creste e da ventri. Se facciamo riferimento alle onde sull’acqua, le creste sono zone in cui il livello dell’acqua è più alto rispetto alla superficie in quiete e i ventri sono zone in cui il livello è più basso. La distanza fra due creste successive (o ventri) è la lunghezza d'onda. Quando l’onda si propaga nell’acqua, i punti del liquido perturbati dall’onda hanno un movimento periodico lungo la verticale. Si chiama ampiezza dell’onda lo spostamento massimo di un punto dalla sua posizione di equilibrio.\n\nIl periodo dell’onda è l’intervallo di tempo che intercorre fra il passaggio di due creste successive (o due ventri) per lo stesso punto. In un mezzo omogeneo l’onda si propaga con velocità costante; il periodo, che indichiamo con T, è il tempo che l’onda impiega a percorrere una lunghezza d’onda. Perciò la velocità dell’onda è:v=\\frac{\\lambda}{T}\n\nLa frequenza dell’onda f, invece, indica quante volte un punto dell’acqua oscilla in un secondo. Poiché la frequenza è il reciproco del periodo (f= 1/T), possiamo anche scrivere l’equazione fondamentale di un’onda come:\n\nIl diagramma seguente mostra in forma grafica la relazione fra la lunghezza d’onda e la frequenza nel campo dell’udibile, cioè fra 20 e 20000 Hz (intervallo di notevole interesse applicativo poiché rappresenta l’intervallo di udibilità dell’Uomo medio).\n\nSi osservi come a 20 Hz, frequenza minima udibile, la lunghezza d’onda corrispondente sia di 17 m mentre a 20.000 Hz è di 17 mm. Queste dimensioni sono importanti nel valutare le interazioni che le onde acustiche hanno con la materia.\n\nIl suono può propagarsi in vari mezzi, e le sue caratteristiche variano in base alla natura del mezzo attraversato:\n\nNei gas (come l’aria): La velocità del suono dipende dalla temperatura e dalla densità del gas. Più alta è la temperatura, maggiore è la velocità del suono, poiché le particelle si muovono più velocemente e trasferiscono l’energia delle onde sonore in modo più efficiente.\n\nNei liquidi (come l’acqua): La velocità del suono è generalmente superiore rispetto ai gas, poiché le molecole sono più vicine tra loro, facilitando la trasmissione delle onde sonore. Nell’acqua, ad esempio, la velocità del suono è di circa 1500 metri al secondo, quasi quattro volte superiore rispetto all’aria.\n\nNei solidi (come i metalli o il legno): Nei materiali solidi, le particelle sono ancora più vicine rispetto ai liquidi, quindi il suono si propaga con una velocità ancora maggiore. Ad esempio, nel ferro la velocità del suono può raggiungere circa 5000 metri al secondo.\n\nNella tabella si riportano alcuni valori della velocità v in m/s per alcune sostanze a temperatura ambiente.","type":"content","url":"/cap1-suono#velocit-e-propagazione-del-suono-nei-diversi-materiali","position":9},{"hierarchy":{"lvl1":"Il suono","lvl3":"Riflessione, rifrazione e diffrazione del Suono","lvl2":"La fisica del suono"},"type":"lvl3","url":"/cap1-suono#riflessione-rifrazione-e-diffrazione-del-suono","position":10},{"hierarchy":{"lvl1":"Il suono","lvl3":"Riflessione, rifrazione e diffrazione del Suono","lvl2":"La fisica del suono"},"content":"Le onde sonore possono subire vari fenomeni fisici quando incontrano ostacoli o cambiano mezzo:\n\nRiflessione: Avviene quando un’onda sonora colpisce una superficie e viene rimandata indietro. Questo fenomeno è alla base dell’eco. Quando un’onda sonora colpisce una superficie dura, come una parete di cemento, parte dell’energia viene riflessa, mentre il resto viene assorbito o trasmesso.\n\nRifrazione: Si verifica quando un’onda sonora passa da un mezzo all’altro e cambia velocità, causando una deviazione della sua traiettoria. Questo effetto è evidente nell’acqua, dove i suoni possono sembrare più vicini o lontani in base alla temperatura e alla densità del mezzo.\n\nDiffrazione: È il fenomeno per cui un’onda sonora riesce a aggirare un ostacolo o a propagarsi attraverso un’apertura, permettendo di sentire suoni anche se non si trova direttamente in linea con la sorgente sonora.\n\nQuando un’onda sonora che si sta propagando in un mezzo materiale incontra la superficie di separazione di un altro mezzo, si possono verificare tre fenomeni: l’onda si riflette; l’onda si trasmette nel secondo mezzo; l’onda viene assorbita dal secondo mezzo. In genere, i tre fenomeni sono presenti contemporaneamente, però uno solo prevale sugli altri due e perciò si parla di riflessione, trasmissione o assorbimento del suono. Per esempio, l’onda sonora che incide su una parete rocciosa viene riflessa e il suono resta nello stesso mezzo da cui proviene. Le onde sonore possono essere trasmesse attraverso un mezzo; per esempio, in un appartamento, il suono è trasmesso attraverso le pareti, i pavimenti, le porte. Infine, se il suono arriva su un materiale che non possiede le caratteristiche di elasticità necessarie, non riesce a propagarsi e in questo caso prevale l’assorbimento. I materiali che si comportano in questo modo sono detti materiali fonoassorbenti. Alcuni esempi di materiali fonoassorbenti sono la moquette, la lana di vetro, il sughero.\n\nSe l’onda sonora incide in direzione perpendicolare alla superficie riflettente torna indietro nella stessa direzione. Se invece la direzione di propagazione dell’onda incidente non coincide con la perpendicolare alla superficie riflettente, l’onda riflessa si propaga in una direzione che forma con la stessa perpendicolare un angolo r uguale a quello di incidenza i (vedi figura).\n\nLa velocità dell’onda incidente è uguale a quella dell’onda riflessa, perché l’onda viaggia nello stesso mezzo. Poiché la frequenza è fissa, per l’equazione dell’onda v =\\lambda f. Questo ci assicura che la lunghezza dell’onda riflessa è identica alla lunghezza d’onda incidente. L’eco è l’esempio più noto di riflessione di onde sonore. Quando lanciamo un grido davanti a una parete verticale posta a opportuna distanza, la parete riflette una parte dell’onda acustica lungo la direzione di incidenza. Dopo qualche istante riceviamo il grido di ritorno, cioè l’eco.\nPoiché la velocità del suono è costante, il tempo che impiega per andare e tornare dalla parete riflettente si calcola con la formula:t=\\frac{2d}{v}\n\ndove d è la distanza della parete (vedi figura).\n\nPerché in una normale stanza non sentiamo l’eco? Per spiegare questo fatto bisogna tener presente che l’orecchio umano distingue due suoni solo se essi gli giungono distanziati nel tempo di almeno un decimo di secondo. Perciò il suono incidente e quello riflesso sulla parete saranno percepiti come distinti solo se il tempo impiegato dal suono per andare e tornare dalla parete è maggiore di un decimo di secondo. Con una velocità di 340 m/s, in un decimo di secondo il suono percorre 34 m.","type":"content","url":"/cap1-suono#riflessione-rifrazione-e-diffrazione-del-suono","position":11},{"hierarchy":{"lvl1":"Il suono","lvl3":"La Percezione del suono e la psicoacustica","lvl2":"La fisica del suono"},"type":"lvl3","url":"/cap1-suono#la-percezione-del-suono-e-la-psicoacustica","position":12},{"hierarchy":{"lvl1":"Il suono","lvl3":"La Percezione del suono e la psicoacustica","lvl2":"La fisica del suono"},"content":"La percezione del suono coinvolge sia la fisica che la biologia. Il nostro sistema uditivo è progettato per captare onde sonore e convertirle in segnali nervosi interpretati dal cervello. Il modo in cui percepiamo il suono è influenzato da molteplici fattori, tra cui:\n\nIntensità: Il volume percepito dipende dall’ampiezza dell’onda sonora. Tuttavia, il nostro orecchio non percepisce le variazioni di intensità in modo lineare, poiché è più sensibile a certe frequenze (specialmente tra i 2.000 e i 5.000 Hz).\n\nFrequenza: Le frequenze comprese tra 20 Hz e 20.000 Hz sono quelle che l’orecchio umano è in grado di percepire. Tuttavia, con l’età, la capacità di udire le frequenze più alte tende a diminuire.\n\nTimbro: È la caratteristica del suono che ci permette di distinguere tra diversi strumenti musicali, anche se suonano la stessa nota. Il timbro dipende dalla presenza di armoniche e dal modo in cui si combinano con la frequenza fondamentale.\n\nLa fisica del suono rappresenta una combinazione affascinante di principi scientifici e applicazioni pratiche, che spaziano dalla musica all’ingegneria acustica, dalla medicina alla tecnologia delle comunicazioni. Comprendere questi principi fondamentali è il primo passo per esplorare in profondità il mondo dell’acustica e le sue infinite possibilità.","type":"content","url":"/cap1-suono#la-percezione-del-suono-e-la-psicoacustica","position":13},{"hierarchy":{"lvl1":"Il suono","lvl2":"Le onde sonore"},"type":"lvl2","url":"/cap1-suono#le-onde-sonore","position":14},{"hierarchy":{"lvl1":"Il suono","lvl2":"Le onde sonore"},"content":"","type":"content","url":"/cap1-suono#le-onde-sonore","position":15},{"hierarchy":{"lvl1":"Il suono","lvl3":"Caratteristiche delle onde sonore","lvl2":"Le onde sonore"},"type":"lvl3","url":"/cap1-suono#caratteristiche-delle-onde-sonore","position":16},{"hierarchy":{"lvl1":"Il suono","lvl3":"Caratteristiche delle onde sonore","lvl2":"Le onde sonore"},"content":"Le onde sonore possono essere descritte tramite alcune caratteristiche fondamentali:\n\nFrequenza (f): È il numero di oscillazioni complete dell’onda in un secondo, misurata in Hertz (Hz). La frequenza determina l’altezza del suono percepito: suoni con frequenze più alte vengono percepiti come acuti, mentre suoni con frequenze più basse vengono percepiti come gravi.\n\nAmpiezza (A): È la misura dell’intensità dell’onda sonora, corrispondente alla quantità di energia trasportata. Un’onda sonora con una maggiore ampiezza sarà percepita come più forte, mentre un’onda con un’ampiezza minore sarà più debole. L’ampiezza si manifesta nell’oscillazione delle particelle nel mezzo di propagazione.\n\nLunghezza d’onda (λ): È la distanza tra due punti consecutivi che si trovano nella stessa fase dell’onda (ad esempio, due compressioni successive). La lunghezza d’onda è inversamente proporzionale alla frequenza: quando la frequenza aumenta, la lunghezza d’onda diminuisce e viceversa.\n\nVelocità del suono (v): La velocità con cui un’onda sonora si propaga dipende dal mezzo attraversato e dalla sua temperatura. Nel caso dell’aria, a temperatura ambiente (circa 20°C), la velocità del suono è di circa 343 metri al secondo. Nei solidi, il suono si propaga più velocemente rispetto ai liquidi e ai gas, poiché le particelle sono più vicine tra loro, facilitando la trasmissione delle vibrazioni.","type":"content","url":"/cap1-suono#caratteristiche-delle-onde-sonore","position":17},{"hierarchy":{"lvl1":"Il suono","lvl3":"Potenza e intensità sonora","lvl2":"Le onde sonore"},"type":"lvl3","url":"/cap1-suono#potenza-e-intensit-sonora","position":18},{"hierarchy":{"lvl1":"Il suono","lvl3":"Potenza e intensità sonora","lvl2":"Le onde sonore"},"content":"La fisica elementare introduce i concetti di energia, potenza, forza, pressione e intensità nella fisica, con particolare attenzione alle loro definizioni e applicazioni.\n\nEnergia. L’energia è la capacità di un sistema di compiere lavoro o di produrre cambiamenti nel sistema stesso o nell’ambiente circostante. È una grandezza scalare e può assumere diverse forme, come energia cinetica (associata al movimento), energia potenziale (associata alla posizione in un campo di forza), energia termica, elettrica, chimica, ecc.\n\nL’unità di misura dell’energia nel Sistema Internazionale (SI) è il joule (J).\n\nEsempio: L’energia immagazzinata in una molla compressa è un esempio di energia potenziale, mentre l’energia che possiede un oggetto in movimento è energia cinetica.\n\nPotenza. La potenza è la quantità di energia trasferita o convertita per unità di tempo. In altre parole, misura la velocità con cui viene compiuto il lavoro o viene trasformata l’energia.\n\nL’unità di misura della potenza è il watt (W), dove 1 watt equivale a 1 joule al secondo (1\\,W = 1\\,J/s).\n\nEsempio: Una lampadina da 60 watt consuma 60 joule di energia ogni secondo per illuminare.\n\nForza. La forza è un’azione che può causare l’accelerazione di un oggetto con massa. È una grandezza vettoriale, il che significa che ha una direzione e un’intensità. Le forze possono provocare il movimento di un corpo, modificarne la velocità o deformarlo.\n\nL’unità di misura della forza è il newton (N), dove 1 newton è definito come la forza necessaria per accelerare un chilogrammo di massa di un metro al secondo quadrato (1\\, N = 1\\, kg\\cdot m/s^2).\n\nEsempio: La forza di gravità che agisce su un oggetto è il peso, e viene calcolata come la massa dell’oggetto moltiplicata per l’accelerazione gravitazionale.\n\nPressione. La pressione è la forza esercitata per unità di superficie. È una grandezza scalare che indica quanto intensamente una forza è distribuita su una determinata area.\n\nL’unità di misura della pressione è il pascal (Pa), dove 1 pascal equivale a 1 newton per metro quadrato (1\\, Pa = 1\\, N/m^2).\n\nEsempio: La pressione atmosferica è la forza che l’aria esercita sulla superficie terrestre, dovuta al peso della colonna d’aria sopra di essa.\n\nIntensità. L’intensità è una misura della potenza trasferita per unità di area. Nella fisica del suono, l’intensità acustica rappresenta la potenza dell’onda sonora che attraversa un’unità di superficie perpendicolare alla direzione di propagazione.\n\nL’unità di misura dell’intensità è il watt per metro quadrato (W/m^2).\n\nEsempio: L’intensità di un suono aumenta quando aumenta l’energia dell’onda sonora, come quando si alza il volume di un altoparlante.\n\nQuesti concetti sono collegati tra loro: la forza può generare pressione, l’energia può essere trasferita attraverso la potenza, e l’intensità può descrivere l’energia trasportata per unità di superficie.\n\nL’ampiezza dell’oscillazione è il parametro più significativo per l’intensità di un suono, cioè l’energia trasportata dall’onda. L’ampiezza di un suono viene misurata in un certo punto dello spazio interessato al passaggio dell’onda. Le particelle d’aria sulla traiettoria dell’onda oscillano rispetto alla posizione di equilibrio: maggiore è l’energia trasportata dall’onda, maggiore sarà lo spostamento della particella d’aria. Una misurazione intuitiva dell’ampiezza è data quindi dall’entità dello spostamento di una particella d’aria nel punto considerato. Tuttavia, questo tipo di misura dà luogo a inconvenienti, in quanto è molto piccola per la maggior parte dei suoni ordinari e la strumentazione non riesce a rilevarla. Esistono altri due tipi di misura a cui si fa di solito riferimento, e che sono strettamente legati: uno è la pressione sonora dell’aria dovuta alla compressione e rarefazione delle particelle (si parla di livello di pressione sonora, o Sound Pressure Level - SPL), l’altro è l’intensità sonora dovuta all’energia trasportata dall’onda sonora (si parla di livello di intensità sonora, o Sound Intensity Level - SIL).\n\nPartiamo dalla pressione sonora. La misura dell’ampiezza di pressione prende in esame la variazione di pressione dell’aria (rispetto alla pressione atmosferica) dovuta a un’onda sonora. Il silenzio puro corrisponde alla pressione atmosferica, la quale varia in modo cosi lento rispetto all’intervento di un’onda sonora da poter essere considerata una costante; un qualsiasi suono causa una variazione di pressione rilevabile. Anche in questo caso la grandezza misurata è irrisoria rispetto alla pressione atmosferica a cui siamo abituati (le variazioni si aggirano intorno a un milionesimo, cioè 1/1.000.000 = 1/10°, della pressione atmosferica). Nonostante ciò, tale quantità è facilmente misurabile con i diaframmi dei microfoni, che, come il timpano dell’orecchio, sono molto sensibili anche a differenze minime di pressione.\n\nIniziamo ora un breve percorso tecnico che, a partire dalla pressione, arriverà a farci comprendere il significato dell’unità di misura comunemente adottata per l’ampiezza, il decibel (dB). Oltre ad alcune nozioni elementari di fisica, occorre far ricorso alla matematica dei logaritmi. La pressione è la forza applicata su una superficie, e quindi viene misurata come la forza per superficie unitaria.  Per avere un’idea intuitiva, la forza esercitata da un carico di ½ Kg corrisponde a circa 5 Newton; in questo caso la direzione è verso il basso (gravità). Il che vuol dire che, se una forza viene applicata a una superficie, la sua efficacia diminuisce con l’aumentare della superficie, in quanto i Newton applicati vanno divisi per i metri quadri. Un esempio classico è dato dal confronto della pressione esercitata su un pavimento da una donna con tacchi a spillo rispetto a un elefante (senza calzature!). Il peso (la forza) di una donna di 50 Kg (cioè circa 500 Newton) applicato a un’area di 2 cm (0,0002 m^2) data dai tacchi a spillo opera una pressione di 2.500.000 N/m^2 (500/0.0002). Il peso (la forza) di un elefante di 1000 Kg (circa 10.000 Newton) viene invece applicato a un’area di 0.1 m^2, causando una pressione di soli 100.000 N/m^2 (10.000/0.1). La pressione operata dalla donna è 25 volte maggiore della pressione operata dall’elefante su un pavimento: su un parquet in legno i tacchi a spillo provocheranno molti più danni della zampa di elefante.\n\nPer comprendere qual è l’ampiezza di pressione per suoni che udiamo tutti i giorni, consideriamo il suono più debole e il suono più forte che una persona media riesce ad ascoltare (soglie di udibilità). Da studi statistici su vaste porzioni di popolazione, la soglia minima dell'udibilità si aggira intorno a 0.000025 N/m^2 (2.5\\times 10^{-5}). La soglia, che come vedremo dipende dalla frequenza, è calcolata per un’onda sinusoidale (tono puro) a una frequenza di 1000 Hz. Il confronto con la pressione  atmosferica salta subito all’occhio: 0.000025 N/m^2 rispetto a 100.000 N/m^2 significa che il più debole segnale udibile corrisponde a una percentuale irrisoria della pressione atmosferica(0.00000025 %). All’altro estremo, la soglia del dolore in cui il suono è così forte da procurare danni irreparabili al timpano, corrisponde a una pressione di circa 30 N/m^2, cioè un milione di volte più grande della soglia minima di udibilità. Tuttavia, il rapporto con la pressione atmosferica è di nuovo irrisorio (circa 0.03 %): cioè anche i suoni più forti arrivano a variazioni di pressione che non vanno oltre pochi centesimi in percentuale rispetto alla pressione atmosferica.\n\nPoiché il rapporto tra un suono appena udibile e un suono alla soglia del dolore fisico è così elevato (circa un milione), conviene schiacciare in qualche modo la scala di riferimento, per avere un’idea significativa delle grandezze relative in gioco. Introduciamo quindi una scala logaritmica, il Livello di Pressione Sonora (Sound Pressure Level - SPI), basata sul rapporto tra due suoni e misurata in decibel. Il Livello di Pressione Sonora SPL è dato dalla relazione:SPL = 20 \\log (p/p_0)\n\nLa scala dei decibel è una scala relativa, nella quale cioè un suono viene misurato in rapporto a un suono di riferimento: p è la pressione del suono da misurare, e p_0 è la pressione del suono di riferimento. La pressione di riferimento p_0 corrisponde alla soglia minima di udibilità definita poc’anzi. Del rapporto tra la pressione p e la pressione p_0, si prende il logaritmo e si moltiplica per 20. Il logaritmo del rapporto si definisce come bel (da Alexander Graham Bell). La moltiplicazione per 20 deve essere interpretata come una moltiplicazione per 10 e poi per 2. La moltiplicazione per 10 esprime la stessa quantita in decibel (cosi come avviene per i metri espressi in decimetri, o i litri in decilitri, moltiplicando per 10). L’ulteriore moltiplicazione per 2 sarà chiara tra qualche istante, quando avremo definito il secondo metodo di misura dell’ampiezza del segnale, che considera l’intensità sonora legata all’energia trasportata dall’onda.\n\nL’intensità sonora è infatti una misura dell’energia trasportata dall’onda: in particolare, come avviene per l’intensità luminosa, l’intensità sonora è l’energia che passa attraverso una superficie unitaria (1\\, m^2) per unità di tempo (1 sec). Poiché l’energia al secondo si misura in W\tatt, l’intensità si misura in Watt/m^2. Nel caso dell’intensità sonora, la scala dei decibel, che assume il nome di Livello di Intensità Sonora (Sound Intensity Level - SIL), è data dalla relazione:SIL = 10 \\log (I/I_0)\n\ndove I è l’intensità del suono in questione e I_0 è il valore di intensità del suono di riferimento. Si tratta di nuovo della soglia minima di intensità per un suono a 1000 Hz di frequenza e vale 0.000000000001 Watt/m^2 (\n\n10-12). poiché SPL e SIL sono valori calcolati in relazione alla soglia di udibilità, nella maggior parte dei suoni standard si ha che i due valori sono identici: non entriamo nei dettagli, ma è opportuno sapere che i due valori differiscono dal punto di vista dell’interpretazione fisica. La pressione è il risultato di onde che arrivano da molteplici direzioni, mentre l’intensità viene definita per una direzione di flusso dell’energia e una superficie attraversata. Il motivo per avere entrambe le misure è che a volte conviene lavorare con l’intensità e altre volte con la pressione, ed è facile, come vedremo subito, passare da una formula all’altra.\n\nPrima di concludere con alcuni valori significativi di ampiezza sonora (vedi Tabella), che daranno un’idea della forza del suono in alcuni casi familiari, occorre precisare cosa avviene con l’introduzione dei decibel.\n\nAbbiamo visto che il decibel non è una quantità di suono, ma un rapporto tra due suoni; per avere una scala assoluta, il rapporto si determina in relazione a un suono sulla soglia dell’udibilità. Prendiamo ora tre suoni qualsiasi x, y e z (vedere le relazioni schematiche in basso). Se l’intensità del suono x è 10 volte maggiore dell’intensità del suono y, allora la differenza tra i livelli di intensità dei due suoni è di 10 decibel (dB). Inoltre, se l’intensità del suono y è 10 volte maggiore dell’intensità del suono z, allora la differenza tra i livelli di intensità dei due suoni è di nuovo di 10 dB. Infine, notiamo che il rapporto tra l’intensità del suono x è 100 volte maggiore dell’intensità del suono z, ma la differenza tra i livelli di intensità del suono x e del suono z è solo di 20 dB.","type":"content","url":"/cap1-suono#potenza-e-intensit-sonora","position":19},{"hierarchy":{"lvl1":"Il suono","lvl3":"Frequenza e altezza del suono","lvl2":"Le onde sonore"},"type":"lvl3","url":"/cap1-suono#frequenza-e-altezza-del-suono","position":20},{"hierarchy":{"lvl1":"Il suono","lvl3":"Frequenza e altezza del suono","lvl2":"Le onde sonore"},"content":"La frequenza di un suono, cioè il numero di vibrazioni complete che la sorgente compie in un secondo, o alternativamente il numero di compressioni/rarefazioni che subisce una particella d’aria in un secondo, è la principale responsabile dell’altezza di un suono. L’altezza di un suono è il parametro legato alla sensazione di gravità/acutezza che si percepisce di un suono. Non tutti i suoni hanno un’altezza definita. L’altezza è una caratteristica che risulta dalla periodicità di un segnale, cioè dal fatto che il segnale ripeta lo stesso andamento per un po’ di tempo, al limite per un tempo infinito. In quest’ultimo caso,infatti, l’altezza\nè ben definita e invariante\te il suono non induce  generalmente\nerrori di giudizio riguardanti la sua altezza (almeno quella relativa). Il diapason approssima molto bene la produzione di questi suoni. I suoni per i quali si parla di altezza per eccellenza sono i suoni musicali di tipo periodico.\n\nQuesto spiega in parte la differenza che sussiste tra un suono puro e un suono complesso. Un suono puro (detto anche tono puro) è costituito da una sola frequenza ed è quindi descritto da un’onda sinusoidale semplice (Figura sotto, in alto); l’andamento del segnale è molto arrotondato; il periodo è composto da una singola compressione e una singola rarefazione ben definite; l’ascolto non è particolarmente interessante. Un suono complesso consiste invece di più frequenze sommate in un’onda dall’andamento articolato (Figura sotto, in basso); in un singolo periodo possono essere comprese più alternanze di compressioni e rarefazioni intermedie; l’ascolto rivela il timbro caratteristico di una sorgente (se esiste in natura o convenzionalmente fissata per i suoni di origine elettronica) e dell’ambiente circostante.\n\nCome vedremo nei prossimi capitoli, un suono complesso qualsiasi contiene molte frequenze. Perché in un suono si possa individuare una frequenza speciale, detta fondamentale, che caratterizza la sensazione globale di gravità/acutezza trasmessa dal suono, occorre che il segnale sia periodico. Un’oscillazione periodica complessa può essere considerata come una somma di una serie di oscillazioni sinusoidali semplici, le cui frequenze costituiscono una progressione aritmetica. Cioè, un segnale periodico lo posso sviluppare come somma di (in)finiti termini armonicamente correlati, ciascuno dei quali è caratterizzato da una frequenza multipla della frequenza fondamentale.","type":"content","url":"/cap1-suono#frequenza-e-altezza-del-suono","position":21},{"hierarchy":{"lvl1":"Il suono","lvl3":"Onde sinusoidali","lvl2":"Le onde sonore"},"type":"lvl3","url":"/cap1-suono#onde-sinusoidali","position":22},{"hierarchy":{"lvl1":"Il suono","lvl3":"Onde sinusoidali","lvl2":"Le onde sonore"},"content":"Una funzione sinusoidale è una rappresentazione matematica di un’onda periodica che può essere utilizzata per descrivere fenomeni oscillatori come il suono, la luce o le onde meccaniche. La forma generale di una funzione sinusoidale nel tempo è:s(t)=A \\sin(2\\pi ft + \\phi) = A\\sin(\\omega t + \\phi)\n\ndove:\n\ns(t) rappresenta il valore dell’onda al tempo t.\n\nA è l’ampiezza della funzione. L’ampiezza rappresenta il massimo valore assoluto raggiunto dalla funzione sinusoidale rispetto alla sua posizione di equilibrio (o valore medio). È una misura dell’intensità o energia dell’onda. Un’onda con ampiezza maggiore avrà oscillazioni più ampie rispetto al punto di equilibrio.\n\nω è la frequenza angolare, espressa in rad/s, e si collega alla frequenza ordinaria f tramite la relazione \\omega=2\\pi f.\n\nt è il tempo. Il tempo è la variabile indipendente della funzione sinusoidale, e rappresenta la progressione dell’onda nel tempo. Man mano che il tempo avanza, la funzione sinusoidale oscilla tra i valori -A e +A con un andamento periodico.\n\nϕ è la fase dell’onda, misurata in radianti. La fase iniziale indica l’offset orizzontale dell’onda al tempo t=0. Se la fase è diversa da zero, l’onda inizia il suo ciclo in un punto diverso rispetto al punto di origine della sinusoide standard (che parte da zero quando \\phi=0). La fase determina quindi lo spostamento orizzontale dell’onda nel grafico.\n\nLa relazione che sussiste tra i parametri ci dice che la combinazione di ampiezza, frequenza e fase determina la forma e il comportamento della funzione sinusoidale. Ad esempio:\n\nCambiando l’ampiezza, si altera l’altezza dell’onda.\n\nCambiando la fase, si sposta l’onda verso sinistra o destra.\n\nModificando la frequenza, si cambia la rapidità con cui l’onda completa i suoi cicli nel tempo.\n\nL’insieme, questi parametri consentono di descrivere accuratamente la natura e il comportamento di onde periodiche in molti ambiti della fisica del suono.","type":"content","url":"/cap1-suono#onde-sinusoidali","position":23},{"hierarchy":{"lvl1":"Il suono","lvl3":"produzione del suono","lvl2":"Le onde sonore"},"type":"lvl3","url":"/cap1-suono#produzione-del-suono","position":24},{"hierarchy":{"lvl1":"Il suono","lvl3":"produzione del suono","lvl2":"Le onde sonore"},"content":"Come detto in precedenza, all’origine di un suono vi è sempre una vibrazione. Tutte le sorgenti sonore (incluse quelle musicali) vibrano: ogni vibrazione completa è detta ciclo. Facciamo riferimento al movimento di una corda fissata alle due estremità (Figura sotto).\n\nLa corda parte da una posizione A (dove si trova a riposo) e si muove verso una direzione. Raggiunta la massima distanza dalla posizione di partenza (punto B), la corda ritorna verso la posizione di equilibrio A. Riprende quindi il cammino in direzione opposta alla precedente, raggiungendo la massima distanza nel punto C. Infine, ritorna verso la posizione di partenza A, e tutto ricomincia. Ogni segnale sonoro comprende molti di questi cicli. I moti di questo tipo in fisica sono detti moti oscillatori. Si ha un moto oscillatorio quando una particella oscilla (o vibra) intorno a una posizione di equilibrio. Moti oscillatori sono il moto di un pendolo, il moto di un peso attaccato a una molla, il moto degli atomi in un corpo solido, il moto della corda in figura. Dei moti oscillatori, il più semplice e, come vedremo, anche il più importante, è il moto armonico semplice, che si ha quando la forza che riporta l’oggetto nella posizione di riposo è proporzionale allo spostamento dell’oggetto. Il pendolo e la massa attaccata a una molla sono tipici esempi di moto armonico semplice.  Se oltre all’informazione sulla posizione della particella vogliamo rappresentare la successione delle variazioni della distanza dall’origine con la variazione dell’angolo a cui si trova la particella occorre disegnare un diagramma cartesiano con una funzione trigonometrica, ad esempio il seno. Il seno di un angolo, infatti, non è altro che la posizione della particella sull’asse verticale rispetto all’origine\n\nLa funzione disegnata descrive quindi un movimento sinusoidale; il fenomeno ondulatorio connesso a tale vibrazione è detto onda seno. Tutta la scienza delle onde sonore è costruita a partire dalle onde sinusoidali. Inseriamo ora il tempo nelle nostre descrizioni. La particella in moto armonico, sia essa una corda o la punta di un diapason, si sposta nel tempo anche se ripete le stesse posizioni. Nella figura si suppone di vincolare un pennino alla punta di un diapason: vibrando, essa disegna nel tempo una curva sinusoidale (simile al funzionamento di un elettrocardiografo).\n\nQuindi, se sull’asse orizzontale rappresentiamo il tempo, la curva che rappresenta la posizione della particella avrà lo stesso andamento sinusoidale. In particolare, l’angolo che corrisponde alla posizione della particella in un certo istante di tempo dipende dalla velocità della vibrazione. In figura vengono rappresentate le caratteristiche importanti dell’oscillazione nel tempo. Innanzitutto, l’ampiezza dell’oscillazione: maggiore è la distanza percorsa dalla particella allontanandosi dalla posizione di equilibrio, maggiore è l’intensità sonora.  L’ampiezza si potrebbe misurare con la distanza massima dalla posizione di equilibrio (quindi in metri) . Suoni deboli (un bisbiglio) compieranno delle oscillazioni molto vicine alla posizione di equilibrio; suoni forti (un’esplosione) compieranno ampie oscillazioni intorno alla posizione di equilibrio. La velocità con cui la particella oscilla, cioè la velocità di rotazione sul cerchio, si misura con il numero di cicli che la particella completa nell’unità di tempo: questa grandezza è la frequenza f che è l’inverso del periodo T. La frequenza è il fattore determinante per l’altezza di un suono: maggiore è la frequenza, più acuto è un suono. Per calcolare la frequenza occorre sapere quanti cicli (e frazioni di ciclo) sono stati completati in un secondo. Questo calcolo necessita della nozione di fase di un segnale. Infatti, la fase indica un istante preciso in un ciclo di un segnale. Per calcolare la frequenza, un ciclo si considera completato tutte le volte che un segnale si presenta nella stessa fase. Poiché un ciclo consta di 360°, un modo per misurare la fase è l’angolo corrispondente all’istante di tempo considerato. Non\nha molto senso considerare la fase di un segnale sinusoidale isolato, ma è importante quando si analizzano le differenze tra più segnali. Se due (o più) onde hanno la stessa frequenza e raggiungono il massimo nello stesso istante, allora le onde si dicono in fase; se viceversa una è al minimo e l’altra è al massimo, le due onde si dicono in opposizione di fase, e presentano una differenza di fase di 180°. In generale, la fase è misurata in gradi di differenza tra le onde (ad esempio, 30°). La fase è particolarmente importante nella spazializzazione del suono, in quanto permette di esprimere una delle differenze che caratterizzano i due segnali percepiti alle due orecchie, ma che riguardano la stessa sorgente sonora. Oltre al periodo, un altro modo alternativo di caratterizzare la velocita di oscillazione di un segnale è la nozione di lunghezza d’onda. La lunghezza d’onda è la distanza tra due punti identici in cicli adiacenti di un segnale. Nel caso delle onde sonore, è la distanza tra due particelle d’aria che si trovano nella stessa fase in cicli adiacenti. Si misura quindi in metri e centimetri. La lunghezza d’onda è inversamente proporzionale alla frequenza: maggiore è la frequenza di un segnale, minore è la sua lunghezza d’onda.","type":"content","url":"/cap1-suono#produzione-del-suono","position":25},{"hierarchy":{"lvl1":"Il suono","lvl3":"Onde stazionarie","lvl2":"Le onde sonore"},"type":"lvl3","url":"/cap1-suono#onde-stazionarie","position":26},{"hierarchy":{"lvl1":"Il suono","lvl3":"Onde stazionarie","lvl2":"Le onde sonore"},"content":"\n\nNella figura qui sopra è illustrata la propagazione di un’onda su una corda fissata alla parete. Quando incontra la parete, l’onda torna indietro. Questo fenomeno si chiama riflessione. Nell’esempio, l’onda riflessa ha la stessa forma di quella incidente sulla parete ma, dove prima c’era una cresta, ora c’è un ventre e viceversa. L’onda risulta ‘capovolta’ rispetto a quella incidente. L’onda che viaggia verso sinistra si riflette e ritorna verso destra; viene riflessa sulla parete di destra e così via. In condizioni ideali, cioè quando l’attrito è trascurabile, l’onda va avanti e indietro fra le due pareti e il movimento continua indefinitamente. Quando l’onda è di tipo sinusoidale e la distanza fra le pareti ha un valore particolare, si ha il fenomeno delle onde stazionarie. L’onda di andata e quella di ritorno si sovrappongono, alcuni punti del mezzo stanno sempre fermi (nodi) e altri punti oscillano con la massima ampiezza (ventri). Il nome deriva dal fatto che l’onda, pur oscillando nel tempo, rimane ferma nella sua posizione. Se pizzichiamo con attenzione la corda di una chitarra nel suo centro possiamo ottenere un moto come quello rappresentato nella figura.\n\nQuesta onda stazionaria ha due punti sempre fissi (detti nodi) agli estremi della corda; tutti gli altri punti della corda si muovono di moto armonico nello stesso verso: o tutti verso l’alto, o tutti verso il basso. Hanno tutti la stessa frequenza\ne si muovono in fase, cioè raggiungono insieme sia il punto massimo dell’oscillazione, sia il punto minimo. Pizzicando opportunamente una corda si possono ottenere onde stazionarie\ncon un numero maggiore di nodi. Per esempio, si possono ottenere onde con due o tre nodi come queste sotto in figura.\n\nLa figura sotto mostra che il primo modo normale di oscillazione, quello con due nodi, ha una lunghezza d’onda \\lambda_1=2L, dove L è la lunghezza della corda che vibra. Il modo normale successivo, con tre nodi, ha lunghezza d’onda \\lambda_2=L. Poi c’è il modo normale con quattro nodi, che ha lunghezza d’onda \\lambda_3=2/3L\n\nIn generale, la lunghezza d’onda del modo normale numero n (che ha n+1 nodi) è \\lambda_n=\\frac{2L}{n},\\qquad n=0,1,2,\\dots\n\n Se indichiamo con v la velocità delle onde sulla corda, possiamo ottenere la frequenza f_n del modo normale numero n:f_n=\\frac{v}{\\lambda_n}=n\\frac{v}{2L},\\qquad n=0,1,2,\\dots\n\nLe frequenze dei modi normali sulla corda sono tutte multipli della frequenzaf_1=\\frac{v}{2L}\n\ndetta fondamentale o prima armonica.Tutte le altre frequenze da f_2 in poi sono multiple di f_1 e sono dette armoniche superiori.\n\n\n\nOnde stazionarie, demo!","type":"content","url":"/cap1-suono#onde-stazionarie","position":27},{"hierarchy":{"lvl1":"Audio digitale"},"type":"lvl1","url":"/cap2-audio","position":0},{"hierarchy":{"lvl1":"Audio digitale"},"content":"","type":"content","url":"/cap2-audio","position":1},{"hierarchy":{"lvl1":"Audio digitale","lvl3":"Introduzione"},"type":"lvl3","url":"/cap2-audio#introduzione","position":2},{"hierarchy":{"lvl1":"Audio digitale","lvl3":"Introduzione"},"content":"Il suono, definito come effetto uditivo, è il risultato della percezione delle vibrazioni sonore da parte di un sistema sensoriale dedicato, come l’orecchio umano o microfoni artificiali. Queste vibrazioni sono generate da sorgenti sonore e si propagano attraverso diversi mezzi, con l’aria che è il più comune, ma anche l’acqua e i solidi come le rocce possono trasmettere suoni in modo simile. In sostanza, il suono nasce in natura come vibrazioni meccaniche, si propaga nella stessa forma e viene percepito come tali. Sin dai tempi antichi, scienziati e inventori hanno cercato di migliorare la propagazione naturale del suono, sviluppando dispositivi artificiali per aumentarne l’efficienza di trasmissione. L’obiettivo era quello di permettere al suono di viaggiare su distanze più lunghe senza subire significativi disturbi, comunemente noti come “rumore”. Inoltre, si è cercato di memorizzare il suono su supporti che permettessero il trasporto nel tempo e nello spazio, consentendo una conservazione permanente delle informazioni sonore.\n\nLa svolta decisiva in questo campo si è avuta con l’invenzione del telefono, attribuita a Antonio Meucci, ma brevettata per primo da Alexander Graham Bell. Questo dispositivo ha rivoluzionato la comunicazione, trasformando i segnali sonori in segnali elettrici, in grado di mantenere gran parte delle informazioni originali del suono. I segnali elettrici possono essere trasmessi più facilmente e rapidamente, inizialmente attraverso cavi elettrici e, successivamente, tramite onde elettromagnetiche con l’avvento della radio, sviluppata da Guglielmo Marconi. Per garantire che il suono potesse essere nuovamente ricostruito all’arrivo, si è stabilita una relazione rigorosa tra il suono originale e le grandezze fisiche associate. Questo processo, noto come trasduzione, consiste nella trasformazione del suono in corrente elettrica, permettendo così di trasmettere informazioni sonore in forma di segnali elettrici. Al ricevitore, questi segnali vengono convertiti nuovamente in suono tramite un altoparlante. La registrazione dei suoni ha seguito principi simili. Utilizzando variazioni di campo magnetico nei registratori a bobina o i parametri fisici dei solchi nei dischi in vinile, i segnali sonori venivano trascritti su supporti fisici.\n\nCon l’avvento delle tecnologie informatiche, la digitalizzazione ha introdotto un nuovo modo di codificare i suoni. In questo caso, i parametri acustici delle onde sonore vengono rappresentati come lunghe sequenze numeriche, dette “digit”, che consentono una rappresentazione precisa dei suoni originali e una riconversione di alta qualità. Il processo di digitalizzazione implica la conversione delle grandezze fisiche continue (analogiche) in serie numeriche di cifre digitali. Queste sequenze numeriche possono essere memorizzate in vari tipi di supporti, come pen drive, hard disk o memorie ottiche (CD, DVD, Blu-Ray), rendendo così possibile il trasporto e la conservazione delle informazioni sonore nel tempo.\n\nÈ importante notare che i segnali digitali differiscono qualitativamente e quantitativamente da quelli analogici. Tuttavia, con una frequenza di campionamento adeguata e una buona connessione durante la trasmissione, le differenze possono risultare impercettibili ai sensi umani, sia nell’udito che nella vista. Attualmente, la conversione del suono in segnali elettrici avviene attraverso l’uso di microfoni, che producono un segnale elettrico ininterrotto quando colpiti da onde sonore. Questo segnale, rappresentato in un certo range di tensione, è considerato un segnale analogico. La conversione in digitale avviene attraverso la lettura ripetuta dei valori di tensione, con l’obiettivo di mantenere una rappresentazione accurata della forma d’onda originale. Il teorema del campionamento stabilisce che, se la frequenza di campionamento è sufficientemente alta, non si perdono informazioni significative.\n\nLe frequenze di campionamento per i segnali audio possono variare da 8000 campioni al secondo per la voce telefonica a 44100 campioni al secondo per audio di qualità musicale. Ogni singolo campione può assumere valori compresi tra un minimo e un massimo, offrendo potenzialmente infiniti valori di lettura. Per completare la conversione analogico-digitale, è necessario suddividere l’intero range dinamico del segnale in intervalli finiti e codificare ciascun intervallo con un valore digitale. Questo processo si compone di due fasi: quantizzazione e codifica. La quantizzazione suddivide il range in intervalli che sono potenze di due, permettendo che ogni campione venga catalogato in uno di questi intervalli e codificato con n bit. Le applicazioni comuni della digitalizzazione utilizzano un minimo di 8 bit per campione per la telefonia e fino a 20 bit o più per la musica, consentendo una rappresentazione fedele del suono originale.\n\nL’aumento dei bit per campione migliora la qualità del segnale e riduce l’impatto del rumore di quantizzazione, ma già 8 bit sono sufficienti per soddisfare gli standard di alta fedeltà (HiFi). La sequenza numerica risultante, nota come segnale audio digitale, contiene tutte le informazioni necessarie per riprodurre fedelmente la forma d’onda elettrica originale, che a sua volta è un’immagine quasi perfetta del suono originale.\n\nInfine, il segnale audio digitale può essere convertito nuovamente in analogico mediante convertitori D/A, permettendo di ottenere la forma elettrica originaria, che, se inviata a un altoparlante, riproduce il suono originale. Sebbene questo processo introduca rumore, le tecnologie moderne consentono di mantenere il rumore a livelli accettabili. Un ulteriore passo consiste nella codifica del segnale audio digitale, che prevede la compressione delle informazioni per ridurre lo spazio occupato. Tecniche di codifica moderne, come lo standard MP3, sono ampiamente utilizzate per la diffusione efficace di musica e suoni in generale.","type":"content","url":"/cap2-audio#introduzione","position":3},{"hierarchy":{"lvl1":"Audio digitale","lvl2":"Segnale audio digitale"},"type":"lvl2","url":"/cap2-audio#segnale-audio-digitale","position":4},{"hierarchy":{"lvl1":"Audio digitale","lvl2":"Segnale audio digitale"},"content":"Come discusso in precedenza, il fenomeno del suono può riferirsi sia a una sensazione uditiva nell’aria sia alla perturbazione in un mezzo che causa tale sensazione. Una domanda interessante è come si passi da tali fenomeni a numeri all’interno di un computer, memorizzati in un array di interi, ad esempio, che possiamo manipolare a piacimento. E poi, se (e in caso affermativo, come) sia possibile ricostruire un segnale acustico partendo da questi numeri.\n\nCome fenomeno fisico, il suono può essere inteso come una vibrazione, come il movimento di molecole che causa variazioni nella pressione di un mezzo, come l’aria che ci circonda. Queste vibrazioni nell’aria possono quindi essere misurate con un microfono, nel quale la variazione di pressione fa muovere un diaframma (supponendo che si tratti di un microfono dinamico). Questo movimento viene poi tradotto in un segnale di tensione tramite una bobina mobile e un magnete. Abbiamo quindi un’idea di come un segnale passi dall’essere movimento di molecole in un gas a un segnale elettrico. Il segnale di tensione prodotto da un microfono è un segnale continuo, cioè può assumere un valore in qualsiasi momento, come accade per la pressione in un punto nello spazio. Inoltre, anche in un istante di tempo specifico, può assumere un numero infinito di valori diversi, anche se l’intervallo è limitato.\n\nIl segnale audio digitale è una rappresentazione discreta di un segnale audio continuo, ottenuta attraverso processi di campionamento e quantizzazione. A differenza del segnale analogico, che varia in modo continuo nel tempo e nell’ampiezza, il segnale digitale è caratterizzato da valori discreti in intervalli di tempo definiti. L’audio digitale sfrutta principi matematici e tecnici per rappresentare segnali continui in forma discreta e comprensibile per le tecnologie digitali. La frequenza di campionamento e la profondità di bit determinano la fedeltà della rappresentazione, mentre il processo di quantizzazione introduce una piccola distorsione inevitabile. Il risultato finale è un segnale che, pur essendo discreto, conserva gran parte delle caratteristiche del segnale analogico originale, consentendo una riproduzione precisa e flessibile.\n\nUn computer può memorizzare solo un numero finito di valori numerici, e tali valori possono assumere solo un numero finito di possibili valori. Quindi, dobbiamo passare dalla misurazione di infiniti valori temporali, che possono assumere un numero infinito di valori diversi, a una rappresentazione finita. In altre parole, dobbiamo passare da segnali analogici a segnali digitali. In relazione a ciò, si pone anche la questione di come possiamo ricostruire i segnali analogici. I processi coinvolti in tutto ciò si chiamano campionamento, quantizzazione e ricostruzione, rispettivamente.\n\nIn termini hardware, un convertitore analogico-digitale (ADC) è un dispositivo, o chip, che converte segnali da analogici a digitali tramite campionamento e quantizzazione, mentre un convertitore digitale-analogico (DAC) converte i segnali digitali in analogici tramite ricostruzione. Nella Figura è mostrato un esempio di sistema di elaborazione audio.\n\nLe vibrazioni nell’aria, rappresentate dal segnale analogico, vengono convertite da un segnale di pressione a uno elettrico dal microfono. Il segnale analogico dal microfono viene poi trasformato in uno digitale tramite l’ADC, dopodiché il segnale digitale può essere elaborato da un computer. Il segnale digitale elaborato può quindi essere convertito in uno analogico tramite il DAC e, infine, riconvertito in un segnale di pressione da inviare, per esempio, ad un altoparlante attivo.\n\nPer quanto riguarda il motivo per cui preferiamo elaborare segnali digitali piuttosto che analogici, ci sono molte ragioni tecniche; le più importanti sono che i computer sono flessibili, possono fare cose che potremmo solo sognare con l’hardware analogico e sono generalmente molto più economici rispetto alla corrispondente soluzione analogica.\n\nLa rappresentazione digitale di un segnale audio analogico come sequenza di numeri è ottenuta tramite un convertitore analogico-digitale (ADC). L’ADC esegue il campionamento delle ampiezze del segnale analogico x(t) su una griglia equidistante lungo l’asse orizzontale del tempo e la quantizzazione delle ampiezze in campioni fissi rappresentati da numeri x(n) lungo l’asse verticale dell’ampiezza (come in figura).\n\nI campioni sono mostrati come linee verticali con punti in alto. Il segnale analogico x(t) indica l’ampiezza del segnale su un tempo continuo t￼in microsecondi. A seguito dell’ADC, il segnale digitale (tempo discreto e ampiezza quantizzata) è una sequenza (flusso) di campioni x(n) rappresentati da numeri sull’indice di tempo discreto n. La distanza temporale tra due campioni consecutivi è chiamata intervallo di campionamento T (periodo di campionamento) e il reciproco è la frequenza di campionamento.\n\nIn questo capitolo, spiegheremo cosa sono il campionamento e la quantizzazione, come funzionano e anche come possiamo ricostruire segnali analogici partendo da quelli digitali.","type":"content","url":"/cap2-audio#segnale-audio-digitale","position":5},{"hierarchy":{"lvl1":"Audio digitale","lvl3":"Campionamento","lvl2":"Segnale audio digitale"},"type":"lvl3","url":"/cap2-audio#campionamento","position":6},{"hierarchy":{"lvl1":"Audio digitale","lvl3":"Campionamento","lvl2":"Segnale audio digitale"},"content":"Il processo di campionamento trasforma un segnale analogico in un segnale discreto, raccogliendo valori a intervalli di tempo regolari. In linea di principio, il teorema di campionamento di Nyquist-Shannon afferma che, affinché un segnale possa essere rappresentato senza ambiguità, la frequenza di campionamento ￼deve essere almeno il doppio della frequenza massima del segnale originale.\n\nSupponiamo di avere un segnale nel tempo continuo, x(t), definito per ogni valore reale di t e che vogliamo elaborare con un DSP. Il processo di campionamento comporta la misurazione del valore di questa funzione in istanti di tempo specifici, t_n, indicizzati da n= 0,1,2,\\dots, per ottenere il segnale x(n)=x(t_n), che chiamiamo segnale a tempo discreto. Il modo più semplice e comune di campionare è il campionamento uniforme, che significa campionare a punti equidistanti, cioè,t_n = T_s n, \\qquad n = 0,1,2,\\dots\n\ndove T_s è il tempo (in secondi) tra due campioni consecutivi ed è chiamato periodo di campionamento. Possiamo osservare che un segnale campionato, o digitale, è in realtà solo una sequenza ordinata di numeri. Più piccolo è T_s, più finemente campioniamo il segnale continuo originale, x(t). Possiamo rappresentare il numero di campioni ottenuti per secondo utilizzando la frequenza di campionamento, definita comef_s=\\frac{1}{T_s}.\n\nLa frequenza di campionamento è misurata in Hertz (Hz). L’audio viene solitamente campionato a 44.1 kHz e oltre, mentre la voce può essere campionata fino a 8 kHz, il che risulta in segnali comprensibili ma certamente non di alta qualità. Nella figura, il processo di campionamento è esemplificato da un segnale continuo, x(t) (blu), che viene campionato per ottenere il segnale a tempo discreto x(n) (rosso).\n\nPer esplorare ulteriormente il campionamento, consideriamo un esempio. Supponiamo che x(t) sia una singola sinusoide di frequenza f in Hertz, cioè,x(t)=\\sin\\left( 2\\pi ft \\right).\n\nUsando la definizione di frequenza di campionamento, otteniamox(n)=\\sin\\left( 2\\pi \\frac{f}{f_s}n \\right)\n\nda cui possiamo definire la seguente quantità\\omega=2\\pi \\frac{f}{f_s}\n\nche chiamiamo frequenza digitale. Essa esprime il numero di radianti per campione. Da una tale frequenza digitale da sola, quindi, non possiamo determinare quale sarebbe la frequenza in Hertz, a meno che non conosciamo la frequenza di campionamento. Una frequenza digitale di \\omega=2\\pi corrisponde alla frequenza di campionamento, indipendentemente dal valore che essa assume. Questo spiega intuitivamente il fatto che un segnale digitale è semplicemente una sequenza di numeri; quindi, senza ulteriori conoscenze, non avremmo modo di dedurre nulla riguardo alla frequenza di campionamento.\n\nOra, la domanda fondamentale che dovremmo porci è questa: quale frequenza di campionamento dobbiamo scegliere per campionare il seno nell’equazione \n\n(3)? Parlando tecnicamente, ciò di cui ci preoccupiamo quando campioniamo è se lo spettro, ossia i contenuti in frequenza, del segnale campionato è lo stesso di quello del segnale continuo originale. Se lo è, significa che abbiamo una rappresentazione digitale perfetta del segnale analogico. Si può dimostrare che se campioniamo il segnale con una frequenza di campionamento che è più del doppio della frequenza del seno, il segnale campionato avrà lo stesso spettro dell’originale. Ora, sorgono un paio di domande. In primo luogo, come generalizziamo questo risultato a qualsiasi segnale, non solo ai seni? La risposta a questa domanda è che, come abbiamo già accennato, (quasi) qualsiasi segnale può essere considerato composto da un numero di seni, e possiamo utilizzare il principio di prima, secondo cui la frequenza di campionamento deve essere più del doppio delle frequenze dei seni. Quindi, se la frequenza più alta di un seno in un segnale è ￼, allora la frequenza di campionamento dovrebbe rispettaref_s>2f_{max}.\n\nQuesto è conosciuto come il teorema di campionamento. A volte, a seconda del campo, è attribuito e denominato in base a diverse persone, tra cui Nyquist, Shannon, Whittaker e Kotelnikov. La seconda domanda è: come possiamo sapere qual è la frequenza massima dei seni nel nostro segnale? La risposta a questa domanda è che generalmente non lo sappiamo. Invece, possiamo semplicemente assicurarci che, per una frequenza di campionamento selezionata, f_s, per il nostro sistema audio, rimuoveremo tutti i contenuti superiormente da f_s/2! Questo viene fatto con un cosiddetto filtro anti-aliasing, che è semplicemente un filtro passa-basso analogico con una frequenza di stop pari a f_s/2, il che significa che tutte le frequenze al di sopra della frequenza di stop vengono rimosse o attenuate. Questo è illustrato in figura.","type":"content","url":"/cap2-audio#campionamento","position":7},{"hierarchy":{"lvl1":"Audio digitale","lvl3":"Aliasing","lvl2":"Segnale audio digitale"},"type":"lvl3","url":"/cap2-audio#aliasing","position":8},{"hierarchy":{"lvl1":"Audio digitale","lvl3":"Aliasing","lvl2":"Segnale audio digitale"},"content":"Diciamo che il segnale è quindi a banda limitata. L’aliasing si riferisce al fenomeno che si verifica quando non rispettiamo il teorema di campionamento. Quando campioniamo a una frequenza di campionamento che è inferiore al doppio della frequenza massima, ciò che accade è che le parti dello spettro al di sopra della metà della frequenza di campionamento si ripiegano attorno alla metà della frequenza di campionamento e appaiono nello spettro inferiore come immagini speculari di sorta. Poiché queste immagini speculari si mescolano con i contenuti in frequenza e non possono essere recuperate o rimosse, abbiamo distorto il nostro segnale. Ad esempio, tornando all’esempio in cui il segnale è un singolo seno, un seno di 5 Hz campionato a 4 Hz subirebbe aliasing e il segnale campionato sarebbe identico a un seno di 1 Hz!, come si nota anche dallo spettro nella figura.\n\nLa frequenza f_s/2 è molto importante, ed è chiamata frequenza di Nyquist. Nella successiva figura, è invece mostrato un esempio di un segnale continuo e del segnale digitale risultante. Il segnale continuo è un seno con una frequenza di 2 Hz ed è campionato a una frequenza di 5 Hz. In quel caso, il teorema di campionamento è soddisfatto, e possiamo vedere che i campioni rappresentano bene il segnale.\n\nPer riassumere le frequenze in gioco nel processo di campionamento, riportiamo in tabella di seguito le principali definizioni e in particolare la loro relazione con l’intervallo di Nyquist.\n\nNella Tabella sotto sono elencate alcune delle frequenze di campionamento audio più comuni e le loro applicazioni. Le moderne schede audio supportano solitamente un’ampia gamma di frequenze di campionamento e sono quindi piuttosto flessibili. È importante notare che, per ragioni tecniche, è spesso vantaggioso utilizzare una frequenza di campionamento più alta nella registrazione originale e durante l’elaborazione rispetto a quella che verrà utilizzata nel prodotto finale, come un CD. Accenniamo brevemente al fatto che il processo di passaggio da una frequenza di campionamento a un’altra, un’operazione comune in molti sistemi audio, si chiama ricampionamento.\n\nFrequenze di campionamento audio comuni e alcuni esempi di applicazioni\n\nFrequenza di campionamento\n\nApplicazioni\n\n8 kHz\n\nNarrowband speech, telephony\n\n16 kHz\n\nWideband speech, telephony, VoIP\n\n44.1 kHz\n\nCD, audio equipment, sound cards\n\n48 kHz\n\nDAT, video recorders\n\n96 kHz\n\nDVD-audio, HD DVD, Blu-ray\n\n192 kHz\n\nDVD-audio, Blu-ray","type":"content","url":"/cap2-audio#aliasing","position":9},{"hierarchy":{"lvl1":"Audio digitale","lvl3":"Quantizzazione","lvl2":"Segnale audio digitale"},"type":"lvl3","url":"/cap2-audio#quantizzazione","position":10},{"hierarchy":{"lvl1":"Audio digitale","lvl3":"Quantizzazione","lvl2":"Segnale audio digitale"},"content":"Come discusso, un segnale analogico misurato in un dato istante, ad esempio n T_s, può, in linea di principio, assumere qualsiasi valore. Tuttavia, abbiamo a disposizione solo un numero finito di bit e quindi un numero finito di valori diversi per rappresentare una misurazione in un computer. Di conseguenza, dobbiamo mappare questo numero infinito di valori su un numero finito di valori. Questo processo è chiamato quantizzazione.  Un modo semplice di quantizzare consiste nel prefissare un un insieme finito di l valori numerici \\{x_1,\\dots,x_l\\} e di associare ad ogni valore campionato x(n), che tipicamente rappresenta una tensione, il valore numerico x_k che è più vicino a x(n). Il passo ulteriore è quello della codifica dei valori dell’insieme \\{x_1,\\dots,x_l\\} in parole binarie di m bit, con risoluzione dipendente dal numero m di bit impiegati.\n\nSe i segnali che prendiamo in considerazione hanno ampiezze comprese tra -V/2 e V/2, la quantizzazione può essere ottenuta dividendo l’insieme \\left[-V/2,V/2\\right] in l intervalli, detti livelli ed attribuendo ad ogni campione x(n)\\in\\left[-V/2,V/2\\right] il centro del livello in cui x(n) cade.  Detti \\{x_1,\\dots,x_l\\} i centri dei vari livelli, l’operazione di quantizzazione può essere allora descritta dalla funzione \\mathcal{Q} che ad ogni x(n) associa il centro più vicino:y(n)=\\mathcal{Q}[x(n)]=\\underset{x_i\\in \\{x_1,\\dots,x_l\\}}{\\arg\\min}|x(n)-x_i|.\n\nIl sistema che realizza l’operazione di quantizzazione è detto quantizzatore e non è in generale un sistema lineare. Poiché inoltre la quantizzazione \\mathcal{Q} è una funzione molti-uno, essa introduce un errore irreversibile nel segnale quantizzato y(n): dato il segnale quantizzato, non è possibile ricostruire in modo esatto il segnale d’origine x(t).\n\nUn sistema quantizzatore in cui l’intervallo [-V/2,V/2] è suddiviso in l livelli di uguale ampiezza V/l, è detto quantizzatore uniforme. In questo caso i livelli hanno dimensione \\Delta=\\frac{V}{l}=x_i-x_{i+1} ,\\quad \\text{con}\\quad 1\\le i\\le l-1,\n\n anche chiamato passo di quantizzazione.\n\nSe abbiamo a disposizione m bit, possiamo rappresentare l=2^{m} livelli i cui centri \\{x_1,\\dots,x_l\\} possono essere codificati con parole di m bit:x_i=b_{i1}\\cdots b_{im},\\qquad \\text{con}\\qquad b_{ik}\\in\\{0,1\\}\\;\\;(1\\le i\\le l)\n\ne il passo di quantizzazione diventa \\Delta = \\frac{V}{2^{m}}.\n\nIl quantizzatore uniforme è il sistema di quantizzazione più comune per l’audio. La dimensione del passo, Δ, ovviamente diminuisce all’aumentare del numero di bit m. Il numero di bit usati per campione nell’audio è tipicamente di 16, 24 o 32 bit. Va notato che quando il segnale in ingresso è al di fuori dell’intervallo specificato [-V/2,V/2], si verifica solitamente un fenomeno di clipping (taglio alla massima capacità di risoluzione), un problema noto che può introdurre un errore arbitrario. Questo significa che tutti i valori del segnale x(n) superiori a V/2 vengono troncati a V/2 e, in modo simile, i valori negativi inferiori a -V/2 vengono troncati a -V/2. Ciò causa artefatti piuttosto gravi e udibili, che dovrebbero essere evitati, ove possibile.\n\nNella figura è illustrato il processo di conversione analogico-digitale mediante un diagramma a blocchi. Il processo comprende il filtraggio del segnale analogico tramite un filtro anti-aliasing, seguito dal campionamento del segnale. Infine, i campioni vengono quantizzati singolarmente.\n\nIl filtro anti-aliasing è un filtro passa-basso che rimuove, o meglio attenua, le frequenze superiori alla metà della frequenza di campionamento. Spesso, questo causa anche una leggera attenuazione delle frequenze vicine alla metà della frequenza di campionamento. Il processo di campionamento causa quindi aliasing dei contenuti di frequenza superiori alla metà della frequenza di campionamento (se presenti), mentre la quantizzazione aggiunge rumore, il cui livello dipende dal numero di bit utilizzati. La Figura seguente mostra il risultato del campionamento (pallino giallo) e campionamento più quantizzazione uniforme a quattro livelli (pallino verde) di un segnale x(t).","type":"content","url":"/cap2-audio#quantizzazione","position":11},{"hierarchy":{"lvl1":"Audio digitale","lvl3":"Errore di quantizzazione e SNR","lvl2":"Segnale audio digitale"},"type":"lvl3","url":"/cap2-audio#errore-di-quantizzazione-e-snr","position":12},{"hierarchy":{"lvl1":"Audio digitale","lvl3":"Errore di quantizzazione e SNR","lvl2":"Segnale audio digitale"},"content":"Una volta fissata la dimensione del passo di quantizzazione Δ, l’intervallo V e il numero di bit m, possiamo definire una funzione che il quantizzatore uniforme applica per mappare i valori di ingresso x(n) ai valori di uscita y(n).  Ogni livello rappresenta un possibile valore di output, in modo che il segnale x(n) sia mappato al livello y(n) più vicino, secondo la seguente espressione:y(n) = \\mathcal{Q}[x(n)] = \\Delta \\cdot \\text{round}\\left(\\frac{x(n)}{\\Delta}\\right),\n\ndove \\text{round}(\\cdot) indica l’arrotondamento al numero intero più vicino. Qui, ogni valore x(n) viene quindi mappato sul livello k-mo di ampiezza Δ che produce l’output y(n)=k\\cdot \\Delta.\n\nL’errore di quantizzazione, e(n), è la differenza tra l’ingresso e l’uscita, ovvero:e(n) = x(n) - y(n) = x(n) - \\mathcal{Q}[x(n)]\n\ne siamo interessati a comprendere l’effetto della quantizzazione sulla qualità del segnale. Un buon modo per capire l’effetto della quantizzazione è il cosiddetto modello di rumore additivo della quantizzazione. Esso afferma che possiamo considerare l’effetto della quantizzazione come l’aggiunta di rumore al segnale di ingresso, ovvero,y(n) = x(n) + e(n)\n\nQuesto è illustrato nella figura precedente in cui si vede l’errore di quantizzazione per un quantizzatore uniforme di due bit (quattro livelli). La quantità di rumore è quindi determinata dalla dimensione del passo Δ. Più piccolo è Δ, minore sarà il rumore aggiunto al segnale. Infatti, possiamo osservare che gli errori di quantizzazione si trovano tra -\\frac{\\Delta}{2} e \\frac{\\Delta}{2}, a causa dell’arrotondamento in \n\n(7). La figura seguente mostra l’errore di quantizzazione per un quantizzatore uniforme di due bit (quattro livelli).\n\nNella figura seguente, invece, è mostrato un istogramma degli errori di quantizzazione per 50000 valori del segnale non periodico (frequenza non razionale f_0=1/(2\\pi 11))\n𝑥(𝑛)= 0.99 \\sin(2\\pi f_0 n) =0.99 \\sin(n/11)\n\nche assume valori compresi tra -1 e 1. Come si nota, l’errore di quantizzazione segue una distribuzione empirica uniforme (istogramma su 50000 campioni) con una dimensione del passo di \\Delta = 0.125. Come si può vedere, i diversi errori si verificano con frequenza approssimativamente uniforme e gli errori sono  -\\frac{\\Delta}{2} \\leq e(n) \\leq \\frac{\\Delta}{2}.\n\nPer analizzare ulteriormente l’effetto della quantizzazione, occorre richiamare il concetto di potenza di un segnale, che per un segnale digitale è la somma calcolata su N campioni:P_x = \\sum_{n=0}^{N-1} x(n)^2.\n\nLa potenza di un segnale è direttamente collegata a quanto forte esso sia percepito: maggiore è la potenza, più alto è il volume percepito. Ora abbiamo compreso cosa rappresenta la potenza di un segnale. Ritornando al modello di rumore additivo della quantizzazione, denotiamo la potenza del segnale di ingresso con P_x e la potenza del rumore con P_e. Una misura della qualità della quantizzazione è il rapporto tra la potenza del segnale di ingresso e quella del rumore, ovvero:\\frac{P_x}{P_e}\n\nQuesto è chiamato rapporto segnale-rumore (SNR, Signal-to-Noise Ratio). Più alto è questo valore, migliore è la nostra quantizzazione e minore sarà l’errore di quantizzazione percepito. Le potenze e i rapporti di potenza sono spesso rappresentati su una scala logaritmica in decibel, e l’SNR è tipicamente calcolato in dB, ovvero\\text{SNR}_{\\text{dB}} = 10 \\cdot \\log_{10} \\left( \\frac{P_x}{P_e} \\right).\n\nPer molti segnali deterministici inoltre l’errore è uniformemente distribuito in \\left[-\\Delta/2,\\Delta/2\\right]. Questo significa che la probabilità che l’errore sia compreso fra e ed e+de è de/\\Delta.  La varianza o potenza del rumore con P_e è allora:P_e=\\sigma_e^2=\\int_{-\\frac{\\Delta}{2}}^{\\frac{\\Delta}{2}}e^2\n\\frac{de}{\\Delta}=\\frac{\\Delta^2}{12}.\n\nIpotizziamo che il segnale di riferimento per il calcolo della potenza sia il segnale sinusoidale analogico x(t)=A\\sin(\\omega\\, t), la cui potenza è del tutto analoga al segnale discreto x(n)=A\\sin(\\omega\\, nT_s). La media di x(t) è 0, poiché:\\lim_{T\\rightarrow \\infty}\\frac{\\int_{-T}^{T}A \\sin(\\omega t)\\,dt}{2T}=0.\n\nLa varianza o potenza del segnale \\sigma_s^2 di x(t) è invece A^2. Infatti per T grande si ha:P_s=\\sigma_s^2=\\frac{1}{2T}\\int_{-T}^{T}(A\\sin(\\omega\\, t)-0)^2\\,\ndt=\\frac{A^2}{2T}\\int_{-T}^{T}(1+\\cos(2\\omega\\, t))\\,dt=A^2.\n\nIn tal caso, se A^2=\\alpha V^2, con \\alpha\\in(0,1):\\begin{align*}\n\\text{SNR}_{\\text{dB}}&=10\\log_{10}12\\alpha \\frac{V^2}{\\Delta^2}\\\\\n&=20\\log_{10}\\frac{V}{\\Delta}+10\\log_{10}12\\alpha\\\\\n&=20\\log_{10}2^{m}+cost\\qquad\\quad(\\text{poiché } \\Delta=V/2^m)\\\\\n&=6.02\\, m+cost\n\\end{align*}\n\nPossiamo concludere con il seguente risultato: in un quantizzatore ogni bit aggiunto comporta un incremento di 6.02 dB al rapporto segnale rumore. Se inoltre il range dinamico A del segnale sfrutta tutto il range V del quantizzatore (cioè \\alpha=1 e A=V) risulta\\text{SNR}_{\\text{dB}}\\approx 6.02\\, m+10.8\\quad \\text{dB.}\n\nLa tabella seguente mostra il livello di miglioramento del rapporto segnale-rumore di un quantizzatore uniforme per gruppi di bit tipicamente usati.\n\n\\text{SNR}_{\\text{dB}} del quantizzatore al variare del numero di bit\n\nNumero bit\n\n\\text{SNR}_{\\text{dB}}\n\nm=8\n\n48 dB\n\nm=10\n\n60 dB\n\nm=16\n\n96 dB","type":"content","url":"/cap2-audio#errore-di-quantizzazione-e-snr","position":13},{"hierarchy":{"lvl1":"Audio digitale","lvl2":"Conversione analogico-digitale (ADC)"},"type":"lvl2","url":"/cap2-audio#conversione-analogico-digitale-adc","position":14},{"hierarchy":{"lvl1":"Audio digitale","lvl2":"Conversione analogico-digitale (ADC)"},"content":"Gli ADC o convertitori analogico-digitale, convertono i valori di tensione in ingresso nel numero corrispondente espresso in binario. La Risoluzione R di un convertitore A/D è definita come la minima variazione della grandezza analogica in ingresso che provoca una variazione di un LSB (Least Significant Bit) nel numero di uscita: tale variazione è definita come quanto Q. La risoluzione R di un ADC coincide, dunque, col quanto Q.","type":"content","url":"/cap2-audio#conversione-analogico-digitale-adc","position":15},{"hierarchy":{"lvl1":"Audio digitale","lvl3":"ADC bipolare","lvl2":"Conversione analogico-digitale (ADC)"},"type":"lvl3","url":"/cap2-audio#adc-bipolare","position":16},{"hierarchy":{"lvl1":"Audio digitale","lvl3":"ADC bipolare","lvl2":"Conversione analogico-digitale (ADC)"},"content":"Un convertitore analogico-digitale bipolare (ADC bipolare) è un tipo di convertitore che può acquisire e convertire segnali analogici sia positivi che negativi in un formato digitale. A differenza degli ADC unipolari, che possono gestire solo segnali positivi, un ADC bipolare è progettato per misurare tensioni che oscillano attorno a zero, come quelle che si trovano spesso nei segnali audio o nelle trasmissioni RF (Radio Frequenza).\n\nEcco i dettagli chiave su come funziona e perché è utile:\n\nGamma di Tensione\n\nGli ADC bipolari hanno un intervallo di misurazione simmetrico che va da un valore negativo massimo a un valore positivo massimo, come  -V_{\\text{ref}}  a  +V_{\\text{ref}} , dove  V_{\\text{ref}}  è la tensione di riferimento.\n\nAd esempio, un ADC bipolare con  V_{\\text{ref}} = 5 \\, \\text{V}  può misurare tensioni nell’intervallo [-5 \\, \\text{V}, +5 \\, \\text{V}].\n\nQuantizzazione e Codifica\n\nPoiché il segnale può essere sia positivo che negativo, l’ADC bipolare utilizza un codice a complemento a due o offset binario per rappresentare i numeri negativi nel formato digitale.\n\nAd esempio, in un ADC a 8 bit, una tensione di 0 \\, \\text{V} potrebbe essere rappresentata da \n\n100000002 (offset binario) o \n\n000000002 (complemento a due), a seconda della codifica scelta.\n\nUso del Bit di Segno\n\nMolti ADC bipolari utilizzano un bit di segno per indicare se il valore misurato è positivo o negativo. Ad esempio, con una codifica a 12 bit, l’ADC può dedicare 11 bit per il valore e 1 bit per il segno, permettendo così una buona risoluzione su un intervallo di tensione completo.\n\nApplicazioni e Vantaggi\n\nGli ADC bipolari sono utili per segnali che oscillano attorno a zero, come segnali audio o segnali AC.\n\nRisultano particolarmente vantaggiosi per segnali analogici bilaterali (che possono variare sopra e sotto zero) e riducono la necessità di pre-elaborazione del segnale per adattarlo all’intervallo di conversione.\n\nEsempio di Implementazione\n\nImmagina un sistema che acquisisce un segnale audio. Un ADC bipolare può convertire l’intero segnale, senza troncare o saturare valori negativi. Se il segnale va da  -2.5 \\, \\text{V}  a  +2.5 \\, \\text{V}  e il sistema ha un ADC a 10 bit con riferimento di  2.5 \\, \\text{V} , ogni valore digitale rappresenta un piccolo intervallo uniforme di tensione (passo di quantizzazione) su tutto l’intervallo bipolare.\n\nIn sintesi, un ADC bipolare è ideale per applicazioni in cui il segnale analogico è bilaterale, garantendo una rappresentazione digitale precisa ed efficiente dei segnali a polarità variabile. In figura si mostra lo schema di funzionamento di un ADC caratterizzato da un full-scale range 𝑅 diviso equamente (per un quantizzatore uniforme) in l=2^𝑞 livelli di quantizzazione. La spaziatura tra i livelli è chiamata Risoluzione del quantizzatore ed è pari a Q=𝑅/2^𝑞.\n\n\nIn figura si mostra un modello di convertitore ADC Sample and Hold (S&H) a q+1 bit di risoluzione, che è un elemento fondamentale nei sistemi di conversione.\n\nQuesto modello consente di “campionare” un segnale analogico in un determinato istante di tempo e di mantenere, o “tenere”, il valore del segnale fino al campionamento successivo, rendendolo disponibile per l’ADC e garantendo una conversione precisa. Questo è essenziale perché il processo di conversione richiede un certo tempo e il segnale può variare rapidamente. In ogni ciclo di campionamento, il circuito S&H esegue due operazioni: la fase di campionamento (Sample) e la fase di mantenimento (Hold). Nella fase di campionamento (Sample) il circuito chiude un interruttore per un breve periodo, consentendo al condensatore (il componente principale per mantenere la tensione) di caricare il valore istantaneo del segnale analogico. Nella fase di mantenimento (Hold) l’interruttore si apre, isolando il condensatore dal segnale in ingresso. Il condensatore ora mantiene (o trattiene) il valore della tensione catturata finché non avviene il campionamento successivo. Le componenti principali sono:\n\nInterruttore: Generalmente realizzato con un transistor MOSFET o un interruttore elettronico, che si apre e chiude per controllare il flusso del segnale al condensatore.\n\nCondensatore: Memorizza la tensione campionata, trattenendola durante la fase di mantenimento. La capacità del condensatore influenza il tempo di mantenimento e la precisione.\n\nBuffer: Spesso è presente un buffer (come un amplificatore operazionale) tra il condensatore e il carico, per evitare che il segnale decada a causa della scarica del condensatore.\n\nLo schema del circuito  è mostrato sotto e lo scopo è quello di acquisire la tensione di ingresso in un determinato istante (campionamento) e di mantenerlo invariato all’uscita fino ad una nuova lettura.\n\nIn sintesi, il modello Sample and Hold è cruciale per isolare e trattenere il segnale analogico prima della conversione digitale, riducendo errori di quantizzazione e migliorando la fedeltà dei dati digitali.","type":"content","url":"/cap2-audio#adc-bipolare","position":17},{"hierarchy":{"lvl1":"Audio digitale","lvl2":"Conversione Digitale-Analogica (DAC)"},"type":"lvl2","url":"/cap2-audio#conversione-digitale-analogica-dac","position":18},{"hierarchy":{"lvl1":"Audio digitale","lvl2":"Conversione Digitale-Analogica (DAC)"},"content":"Un convertitore DAC (Digital-to-Analog Converter) è un dispositivo che trasforma segnali digitali in segnali analogici. Questa conversione è fondamentale per applicazioni in cui segnali digitali devono essere presentati o utilizzati in un ambiente analogico, come in dispositivi audio, video, comunicazioni, e attuatori di controllo. Il Principio di Funzionamento di un DAC è il seguente.\n\nIl DAC prende una sequenza di numeri digitali, che rappresentano il valore discreto del segnale, e li converte in una tensione o corrente continua che varia analogamente ai valori digitali di ingresso.\n\nOgni numero digitale (tipicamente espresso in bit) corrisponde a un livello di tensione specifico in uscita. Maggiore è il numero di bit, maggiore sarà la risoluzione del segnale analogico, poiché ogni bit aggiunto permette di raddoppiare i livelli di tensione rappresentabili.\n\nLa trasformazione di bit in livelli di tensione in un convertitore digitale-analogico (DAC) avviene assegnando a ogni combinazione di bit un valore di tensione corrispondente, che rispecchia l’informazione digitale in un formato analogico.","type":"content","url":"/cap2-audio#conversione-digitale-analogica-dac","position":19},{"hierarchy":{"lvl1":"Audio digitale","lvl4":"Codifica Binaria e Livelli di Tensione","lvl2":"Conversione Digitale-Analogica (DAC)"},"type":"lvl4","url":"/cap2-audio#codifica-binaria-e-livelli-di-tensione","position":20},{"hierarchy":{"lvl1":"Audio digitale","lvl4":"Codifica Binaria e Livelli di Tensione","lvl2":"Conversione Digitale-Analogica (DAC)"},"content":"In un sistema digitale a m bit, ogni configurazione dei bit rappresenta un valore discreto, compreso tra 0 e 2^{m}-1.\n\nL’intervallo di tensione totale del DAC è definito dai valori di tensione V_{\\text{min}} e V_{\\text{max}}, dove V_{\\text{min}} è il livello di tensione più basso (di solito 0 V) e V_{\\text{max}} il livello più alto.\n\nIl passo di quantizzazione \\Delta V=(V_{\\text{max}}-V_{\\text{max}})/(2^{q}-1) è la differenza di tensione tra due livelli consecutivi\n\nLa precisione del DAC è legata al numero di bit e alla stabilità dei livelli di tensione. Più bit ha il DAC, più livelli di tensione può rappresentare e quindi maggiore è la risoluzione, riducendo la differenza tra livelli di quantizzazione (\\Delta V) e rendendo la rappresentazione analogica più fedele all’originale digitale.\n\nIn sintesi, un DAC trasforma combinazioni di bit in livelli di tensione specifici usando un passo di quantizzazione per mappare ciascun valore binario a un livello di tensione proporzionale, permettendo così di convertire segnali digitali in forma analogica per molteplici applicazioni.","type":"content","url":"/cap2-audio#codifica-binaria-e-livelli-di-tensione","position":21},{"hierarchy":{"lvl1":"Audio digitale","lvl3":"Conversione unipolare","lvl2":"Conversione Digitale-Analogica (DAC)"},"type":"lvl3","url":"/cap2-audio#conversione-unipolare","position":22},{"hierarchy":{"lvl1":"Audio digitale","lvl3":"Conversione unipolare","lvl2":"Conversione Digitale-Analogica (DAC)"},"content":"Nella conversione unipolare, il DAC Unipolare converte i segnali digitali in livelli di tensione che si trovano esclusivamente in un intervallo positivo o zero-positivo. Questo tipo di conversione è tipico in applicazioni dove l’intervallo di tensione deve essere limitato, ad esempio tra 0 e V_{\\text{max}}. Il circuito di un convertitore a scala R-2R a quattro bit, tra i più diffusi anche in ambito audio, è quello di figura.\n\nPer ottenere la tensione in uscita V_{out} per una configurazione di bit specifica b_1,\\dots,b_m (un valore binario tra 0 e 2^m-1), la formula è:V_{out}=\\frac{V_{\\text{ref}}}{2^m}(𝑏_0 2^{0}+𝑏_1 2^{1}+\\cdots+b_{N-1}2^{N-1})=\\frac{V_{\\text{ref}}}{2^m}D\n\ndove D\\in\\{0,1,\\dots,2^m-1\\}.","type":"content","url":"/cap2-audio#conversione-unipolare","position":23},{"hierarchy":{"lvl1":"Informazione MultiMediale - Audio -"},"type":"lvl1","url":"/intro","position":0},{"hierarchy":{"lvl1":"Informazione MultiMediale - Audio -"},"content":"Dispensa del corso di Informazione MultiMediale - Audio (AA 2024-25)\n\nLaurea in Informatica per la Comunicazione Digitale","type":"content","url":"/intro","position":1}]}